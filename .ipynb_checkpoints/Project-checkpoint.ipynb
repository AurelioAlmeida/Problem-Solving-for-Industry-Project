{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7692d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49152aa0",
   "metadata": {},
   "source": [
    "#### Define the path to collect and save PDF files from One drive to Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f433b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the OneDrive directory paths\n",
    "onedrive_path_1 = \"/Users/rennersantana/OneDrive - TestReach/Briefs\"\n",
    "onedrive_path_2 = \"/Users/rennersantana/OneDrive - TestReach/Briefs/On-demand exam briefs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1958e",
   "metadata": {},
   "source": [
    "#### Path to save collected PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ddf3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save the collected PDF files\n",
    "save_path = \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378eb58",
   "metadata": {},
   "source": [
    "#### Collect PDF files recursively from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c886c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect PDF files recursively from a directory\n",
    "def collect_pdf_files(directory):\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "    return pdf_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3834c2fa",
   "metadata": {},
   "source": [
    "#### Copy PDf files to a specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d45dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy PDF files to a specified directory\n",
    "def copy_pdf_files(pdf_files, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for pdf_file in pdf_files:\n",
    "        shutil.copy(pdf_file, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c433ef",
   "metadata": {},
   "source": [
    "#### Here we collect the PDf files from both directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "891b27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we collect the PDF files from both directories\n",
    "pdf_files_1 = collect_pdf_files(onedrive_path_1)\n",
    "pdf_files_2 = collect_pdf_files(onedrive_path_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bea14d",
   "metadata": {},
   "source": [
    "#### Combine the lists of PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb950f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the lists of PDF files\n",
    "pdf_files = pdf_files_1 + pdf_files_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd314fe",
   "metadata": {},
   "source": [
    "#### Copy PDF files to a specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16a7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy PDF files to the specified directory\n",
    "copy_pdf_files(pdf_files, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd2e781",
   "metadata": {},
   "source": [
    "#### Print the list of collected PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f6ffdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF files copied to: /Users/rennersantana/Desktop/AI - ChatBot/PDF_Files\n"
     ]
    }
   ],
   "source": [
    "# Print the list of collected PDF files\n",
    "print(\"PDF files copied to:\", save_path)\n",
    "#for pdf_file in pdf_files:\n",
    "    #print(pdf_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9ac67",
   "metadata": {},
   "source": [
    "#### Now we can start creating the questions for the bot and to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab240f",
   "metadata": {},
   "source": [
    "#### Set the directory containing PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b9bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing PDF files\n",
    "pdf_directory = \"/Users/rennersantana/OneDrive - TestReach/Briefs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bbcbd1",
   "metadata": {},
   "source": [
    "#### Check if the directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f484b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the PDF directory exists; if not, print a message.\n",
    "if not os.path.exists(pdf_directory):\n",
    "    print(f\"Directory '{pdf_directory}' does not exist.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604df987",
   "metadata": {},
   "source": [
    "#### Defining function to collect Specific Information from PDf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b68ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to collect specific information from PDF files\n",
    "def extract_information_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        # Initialize variables to store extracted information\n",
    "        on_screen_calculator = \"Not Available\"\n",
    "        on_screen_notepad = \"Not Available\"\n",
    "        comfort_breaks = \"Not Allowed\"\n",
    "        identification = {\n",
    "            \"Passport\": \"Not Available\",\n",
    "            \"Driver’s License\": \"Not Available\",\n",
    "            \"National ID card\": \"Not Available\",\n",
    "            \"EU ID card\": \"Not Available\",\n",
    "            \"Work ID\": \"Not Available\"\n",
    "        }\n",
    "        # Loop through each page of the PDF to extract information\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            # Extract on-screen calculator information\n",
    "            if \"On Screen Calculator: Available\" in text:\n",
    "                on_screen_calculator = \"Available\"\n",
    "            # Extract on-screen notepad information\n",
    "            if \"On Screen Notepad: Available\" in text:\n",
    "                on_screen_notepad = \"Available\"\n",
    "            # Extract comfort breaks information\n",
    "            if \"Comfort Breaks\" in text:\n",
    "                if any(phrase in text for phrase in [\"Allowed\", \"Y\", \"YES\", \"yes\"]):\n",
    "                    comfort_breaks = \"Allowed\"\n",
    "                else:\n",
    "                    comfort_breaks = \"Not Allowed\"\n",
    "            # Extract identification information\n",
    "            for item in identification:\n",
    "                if item in text:\n",
    "                    start_idx = text.find(item)\n",
    "                    end_idx = text.find(\"\\n\", start_idx)\n",
    "                    line = text[start_idx:end_idx]\n",
    "                    if any(phrase in line for phrase in [\"Y\", \"YES\", \"yes\", \"Allowed\", \"Not Allowed\", \"allowed\", \"not allowed\"]):\n",
    "                        identification[item] = \"Yes\" if any(phrase in line for phrase in [\"Y\", \"YES\", \"yes\", \"Allowed\", \"allowed\"]) else \"No\"\n",
    "        # Return the extracted information\n",
    "        return on_screen_calculator, on_screen_notepad, comfort_breaks, identification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e23cea",
   "metadata": {},
   "source": [
    "#### Initialise lists to store extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3443b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store extracted information\n",
    "filename_list = []\n",
    "calculator_list = []\n",
    "notepad_list = []\n",
    "comfort_breaks_list = []\n",
    "passport_list = []\n",
    "drivers_license_list = []\n",
    "national_id_card_list = []\n",
    "eu_id_card_list = []\n",
    "work_id_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379bf59b",
   "metadata": {},
   "source": [
    "#### Loop through each PDf file in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccd9c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each PDF file in the directory\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_file = os.path.join(pdf_directory, filename)\n",
    "        # Extract information from the current PDF file\n",
    "        on_screen_calculator, on_screen_notepad, comfort_breaks, identification = extract_information_from_pdf(pdf_file)\n",
    "        # Append extracted information to lists\n",
    "        filename_list.append(filename)\n",
    "        calculator_list.append(on_screen_calculator)\n",
    "        notepad_list.append(on_screen_notepad)\n",
    "        comfort_breaks_list.append(comfort_breaks)\n",
    "        passport_list.append(identification[\"Passport\"])\n",
    "        drivers_license_list.append(identification[\"Driver’s License\"])\n",
    "        national_id_card_list.append(identification[\"National ID card\"])\n",
    "        eu_id_card_list.append(identification[\"EU ID card\"])\n",
    "        work_id_list.append(identification[\"Work ID\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b28b393",
   "metadata": {},
   "source": [
    "#### Create a DataFrame to store extracted information in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bee6fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the extracted information\n",
    "data = {\n",
    "    \"Filename\": filename_list,\n",
    "    \"On Screen Calculator\": calculator_list,\n",
    "    \"On Screen Notepad\": notepad_list,\n",
    "    \"Comfort Breaks\": comfort_breaks_list,\n",
    "    \"Passport\": passport_list,\n",
    "    \"Driver’s License\": drivers_license_list,\n",
    "    \"National ID card\": national_id_card_list,\n",
    "    \"EU ID card\": eu_id_card_list,\n",
    "    \"Work ID\": work_id_list\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc40d1d",
   "metadata": {},
   "source": [
    "#### Path to save the CSV file once extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a118c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to save the CSV file\n",
    "csv_file_path = \"/Users/rennersantana/Desktop/AI - ChatBot/extracted_information.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70a8ff",
   "metadata": {},
   "source": [
    "#### Save DataFrame to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a4dd2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3b3d4",
   "metadata": {},
   "source": [
    "#### Print confirmation file was saved in the specific path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65863543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted information saved to: /Users/rennersantana/Desktop/AI - ChatBot/extracted_information.csv\n"
     ]
    }
   ],
   "source": [
    "# Print confirmation message\n",
    "print(\"Extracted information saved to:\", csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72469f7",
   "metadata": {},
   "source": [
    "#### Preprocessing the data - After extract informations from PDF and created a dataset csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1fd24a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Here's a preview:\n",
      "                                            Filename On Screen Calculator  \\\n",
      "0                             EMA 23 April, 2024.pdf            Available   \n",
      "1                              CIIA 2nd May 2024.pdf        Not Available   \n",
      "2                      PMI 8 May,2024 CPTU2 Exam.pdf        Not Available   \n",
      "3  SRB - Exam Brief_Senior Bank Resolution Expert...        Not Available   \n",
      "4            BACP Exam Brief - May 2024 sessions.pdf        Not Available   \n",
      "\n",
      "  On Screen Notepad Comfort Breaks Passport Driver’s License National ID card  \\\n",
      "0         Available    Not Allowed      Yes              Yes              Yes   \n",
      "1     Not Available    Not Allowed      Yes              Yes              Yes   \n",
      "2     Not Available    Not Allowed      Yes              Yes    Not Available   \n",
      "3         Available    Not Allowed      Yes              Yes              Yes   \n",
      "4     Not Available    Not Allowed      Yes              Yes              Yes   \n",
      "\n",
      "      EU ID card        Work ID  \n",
      "0            Yes  Not Available  \n",
      "1  Not Available            Yes  \n",
      "2  Not Available  Not Available  \n",
      "3            Yes  Not Available  \n",
      "4  Not Available            Yes  \n",
      "\n",
      "Text data standardized. Here's a preview:\n",
      "                                            Filename On Screen Calculator  \\\n",
      "0                             EMA 23 April, 2024.pdf            Available   \n",
      "1                              CIIA 2nd May 2024.pdf        Not Available   \n",
      "2                      PMI 8 May,2024 CPTU2 Exam.pdf        Not Available   \n",
      "3  SRB - Exam Brief_Senior Bank Resolution Expert...        Not Available   \n",
      "4            BACP Exam Brief - May 2024 sessions.pdf        Not Available   \n",
      "\n",
      "  On Screen Notepad Comfort Breaks Passport Driver’s License National ID card  \\\n",
      "0         Available    Not Allowed      Yes              Yes              Yes   \n",
      "1     Not Available    Not Allowed      Yes              Yes              Yes   \n",
      "2     Not Available    Not Allowed      Yes              Yes    Not Available   \n",
      "3         Available    Not Allowed      Yes              Yes              Yes   \n",
      "4     Not Available    Not Allowed      Yes              Yes              Yes   \n",
      "\n",
      "      EU ID card        Work ID  \n",
      "0            Yes  Not Available  \n",
      "1  Not Available            Yes  \n",
      "2  Not Available  Not Available  \n",
      "3            Yes  Not Available  \n",
      "4  Not Available            Yes  \n",
      "\n",
      "Categorical data encoded. Here's a preview of the new columns:\n",
      "Index(['Filename', 'On Screen Calculator_Available',\n",
      "       'On Screen Calculator_Not Available', 'On Screen Notepad_Available',\n",
      "       'On Screen Notepad_Not Available', 'Comfort Breaks_Allowed',\n",
      "       'Comfort Breaks_Not Allowed', 'Passport_Not Available', 'Passport_Yes',\n",
      "       'Driver’s License_Not Available', 'Driver’s License_Yes',\n",
      "       'National ID card_Not Available', 'National ID card_Yes',\n",
      "       'EU ID card_Not Available', 'EU ID card_Yes', 'Work ID_Not Available',\n",
      "       'Work ID_Yes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"/Users/rennersantana/Desktop/AI - ChatBot/extracted_information.csv\")\n",
    "print(\"Data loaded successfully. Here's a preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Standardizing text data\n",
    "df['On Screen Calculator'] = df['On Screen Calculator'].str.title()  # Ensures consistent casing\n",
    "df['On Screen Notepad'] = df['On Screen Notepad'].str.title()\n",
    "df['Comfort Breaks'] = df['Comfort Breaks'].str.title()\n",
    "print(\"\\nText data standardized. Here's a preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Encoding categorical data using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=[\n",
    "    'On Screen Calculator', 'On Screen Notepad', 'Comfort Breaks',\n",
    "    'Passport', 'Driver’s License', 'National ID card', 'EU ID card', 'Work ID'\n",
    "])\n",
    "print(\"\\nCategorical data encoded. Here's a preview of the new columns:\")\n",
    "print(df_encoded.columns)\n",
    "\n",
    "# Save the preprocessed data\n",
    "df_encoded.to_csv(\"/Users/rennersantana/Desktop/AI - ChatBot/preprocessed_extracted_information.csv\", index=False)\n",
    "# print(\"\\nPreprocessed data saved to '/Users/rennersantana/Desktop/AI - ChatBot/preprocessed_extracted_information.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a23111",
   "metadata": {},
   "source": [
    "#### Creating the questions for the chatbot to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "353bec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "# Dictionary mapping questions to dataset columns\n",
    "questions_to_columns = {\n",
    "    \"Is an on-screen calculator available during the exam?\": \"On Screen Calculator_Available\",\n",
    "    \"Is there an on-screen notepad available?\": \"On Screen Notepad_Available\",\n",
    "    \"Are comfort breaks allowed during the exam?\": \"Comfort Breaks_Allowed\",\n",
    "    \"Do I need a passport to take the exam?\": \"Passport_Yes\",\n",
    "    \"Can I use my driver’s license as identification for the exam?\": \"Driver’s License_Yes\",\n",
    "    \"Do I need a national ID card to take the exam?\": \"National ID card_Yes\",\n",
    "    \"Can I use my EU ID card as identification for the exam?\": \"EU ID card_Yes\",\n",
    "    \"Is a work ID an acceptable form of identification for the exam?\": \"Work ID_Yes\"\n",
    "}\n",
    "\n",
    "# Function to answer questions based on dataset\n",
    "def answer_question(question, data_frame):\n",
    "    # Get the column corresponding to the question\n",
    "    column = questions_to_columns.get(question, \"\")\n",
    "    if column:\n",
    "        # Assume data_frame is the row of interest, for example, the first row\n",
    "        return \"Yes\" if data_frame.iloc[0][column] else \"No\"\n",
    "    else:\n",
    "        return \"I don't have information about that.\"\n",
    "\n",
    "# Here I set up an example usage\n",
    "import pandas as pd\n",
    "df_encoded = pd.read_csv(\"/Users/rennersantana/Desktop/AI - ChatBot/preprocessed_extracted_information.csv\")\n",
    "sample_question = \"Is an on-screen calculator available during the exam?\"\n",
    "print(answer_question(sample_question, df_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19464e2",
   "metadata": {},
   "source": [
    "#### Creating different types of questions to expand the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional variations of existing questions\n",
    "additional_questions = {\n",
    "    \"Can I use a calculator during the test?\": \"On Screen Calculator_Available\",\n",
    "    \"Is notepad functionality enabled during the test?\": \"On Screen Notepad_Available\",\n",
    "    # Add more variations and related questions here\n",
    "}\n",
    "questions_to_columns.update(additional_questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16107ec",
   "metadata": {},
   "source": [
    "#### Using some machine learning and NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652de37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load SpaCy's English tokenizer with lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client = OpenAI(api_key='api-key-here')\n",
    "\n",
    "# Load the preprocessed data\n",
    "df_encoded = pd.read_csv(\"/Users/rennersantana/Desktop/AI - ChatBot/preprocessed_extracted_information.csv\")\n",
    "\n",
    "# Define a function to preprocess questions with lemmatization\n",
    "def preprocess_text(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "# Setup vectorization and NLP processing\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "questions_to_columns = {\n",
    "    \"Is an on-screen calculator available during the exam?\": \"On Screen Calculator_Available\",\n",
    "    \"Is there an on-screen notepad available?\": \"On Screen Notepad_Available\",\n",
    "}\n",
    "questions = list(questions_to_columns.keys())\n",
    "processed_questions = [preprocess_text(question) for question in questions]\n",
    "question_vectors = vectorizer.fit_transform(processed_questions)\n",
    "\n",
    "def find_closest_question(user_query, threshold=0.75):  # Adjusted threshold\n",
    "    processed_query = preprocess_text(user_query)\n",
    "    query_vector = vectorizer.transform([processed_query])\n",
    "    similarities = cosine_similarity(query_vector, question_vectors)\n",
    "    max_similarity = max(similarities[0])\n",
    "    if max_similarity < threshold:\n",
    "        return None\n",
    "    return questions[similarities.argmax()]\n",
    "\n",
    "def answer_question(question, data_frame):\n",
    "    matched_question = find_closest_question(question)\n",
    "    if matched_question:\n",
    "        column = questions_to_columns[matched_question]\n",
    "        response = \"Yes, it is available.\" if data_frame.iloc[0][column] else \"No, it is not available.\"\n",
    "    else:\n",
    "        # Fallback to GPT if no direct match is found\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": question}],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "        response = response.choices[0].message.content.strip()\n",
    "    return response\n",
    "\n",
    "# Chatbot interaction loop\n",
    "print(\"Welcome to the Exam Info Chatbot! Ask me anything about exam provisions. Type 'quit' to exit.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        print(\"Thank you for using the Chatbot. Goodbye!\")\n",
    "        break\n",
    "    response = answer_question(user_input, df_encoded)\n",
    "    print(\"Chatbot: \", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768852d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af049b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a267ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
