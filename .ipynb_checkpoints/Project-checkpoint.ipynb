{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7692d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import shutil\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49152aa0",
   "metadata": {},
   "source": [
    "#### Define the path to collect and save PDF files from One drive to Local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9930a",
   "metadata": {},
   "source": [
    "#### We use onedrive to collect PDFs files from the cloud and save it locally so we can use it later to build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f433b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the OneDrive directory paths\n",
    "onedrive_path_1 = \"/Users/rennersantana/OneDrive - TestReach/Briefs\"\n",
    "onedrive_path_2 = \"/Users/rennersantana/OneDrive - TestReach/Briefs/On-demand exam briefs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1958e",
   "metadata": {},
   "source": [
    "#### Define the path where the PDF files are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ddf3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save the collected PDF files\n",
    "save_path = \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378eb58",
   "metadata": {},
   "source": [
    "#### Collect PDF files recursively from the directory set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect PDF files recursively from a directory\n",
    "def collect_pdf_files(directory):\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "    return pdf_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3834c2fa",
   "metadata": {},
   "source": [
    "#### Copy PDf files to a specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d45dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy PDF files to a specified directory\n",
    "def copy_pdf_files(pdf_files, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for pdf_file in pdf_files:\n",
    "        shutil.copy(pdf_file, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c433ef",
   "metadata": {},
   "source": [
    "#### PDFs are collected from the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we collect the PDF files from both directories\n",
    "pdf_files_1 = collect_pdf_files(onedrive_path_1)\n",
    "pdf_files_2 = collect_pdf_files(onedrive_path_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bea14d",
   "metadata": {},
   "source": [
    "#### Combine the lists of PDF from the two folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb950f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the lists of PDF files\n",
    "pdf_files = pdf_files_1 + pdf_files_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd314fe",
   "metadata": {},
   "source": [
    "#### Copy PDF files to a specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy PDF files to the specified directory\n",
    "copy_pdf_files(pdf_files, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd2e781",
   "metadata": {},
   "source": [
    "#### Print the list of collected PDF files and store it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of collected PDF files\n",
    "print(\"PDF files copied to:\", save_path)\n",
    "#for pdf_file in pdf_files:\n",
    "    #print(pdf_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9ac67",
   "metadata": {},
   "source": [
    "#### After saved the files to the drive of choice the dataset will start to be build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab240f",
   "metadata": {},
   "source": [
    "#### Set the directory containing PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing PDF files\n",
    "pdf_directory = \"/Users/rennersantana/OneDrive - TestReach/Briefs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bbcbd1",
   "metadata": {},
   "source": [
    "#### Check if the directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f484b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the PDF directory exists; if not, print a message.\n",
    "if not os.path.exists(pdf_directory):\n",
    "    print(f\"Directory '{pdf_directory}' does not exist.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604df987",
   "metadata": {},
   "source": [
    "#### Defining function to collect peace of Informations from PDF files\n",
    "#### Mapping of original organisation names to anonymize  the name of orgs for privacy and security reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "\n",
    "# Mapping of original organization names to anonymized identifiers\n",
    "org_mapping = {\n",
    "    \"ABP Brief 26 April, 2024.pdf\": \"#001\",\n",
    "    \"ABDO 13 May,2024.pdf\": \"#002\",\n",
    "    \"EMA 23 April, 2024.pdf\": \"#003\",\n",
    "    \"CIIA 2nd May 2024.pdf\": \"#004\",\n",
    "    \"PMI 8 May,2024 CPTU2 Exam.pdf\": \"#005\",\n",
    "    \"SRB - Exam Brief_Senior Bank Resolution Expert_SRB AD 2023 006_Profile 2.docx.pdf\": \"#006\"\n",
    "}\n",
    "\n",
    "# Here it extracts specific info from a PDF file\n",
    "def extract_information_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        # Initialize default values for the info we want to extract\n",
    "        on_screen_calculator = \"Not Available\"\n",
    "        on_screen_notepad = \"Not Available\"\n",
    "        comfort_breaks = \"Not Allowed\"\n",
    "        identification = {\n",
    "            \"Passport\": \"Not Available\",\n",
    "            \"Driver’s License\": \"Not Available\",\n",
    "            \"National ID card\": \"Not Available\",\n",
    "            \"EU ID card\": \"Not Available\",\n",
    "            \"Work ID\": \"Not Available\"\n",
    "        }\n",
    "        # Get the filename from the file path\n",
    "        filename = pdf_file.split(\"/\")[-1]\n",
    "        # Replace org name with anonymized identifier\n",
    "        filename_anonymized = org_mapping.get(filename, filename)\n",
    "        \n",
    "        # Loop through each page in the PDF to find the info we need\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            # Check if on-screen calculator is available\n",
    "            if \"On Screen Calculator: Available\" in text:\n",
    "                on_screen_calculator = \"Available\"\n",
    "            # Check if on-screen notepad is available\n",
    "            if \"On Screen Notepad: Available\" in text:\n",
    "                on_screen_notepad = \"Available\"\n",
    "            # Check if comfort breaks are allowed\n",
    "            if \"Comfort Breaks\" in text:\n",
    "                if any(phrase in text for phrase in [\"Allowed\", \"Y\", \"YES\", \"yes\"]):\n",
    "                    comfort_breaks = \"Allowed\"\n",
    "                else:\n",
    "                    comfort_breaks = \"Not Allowed\"\n",
    "            # Check the availability of different types of identification\n",
    "            for item in identification:\n",
    "                if item in text:\n",
    "                    start_idx = text.find(item)\n",
    "                    end_idx = text.find(\"\\n\", start_idx)\n",
    "                    line = text[start_idx:end_idx]\n",
    "                    if any(phrase in line for phrase in [\"Y\", \"YES\", \"yes\", \"Allowed\", \"Not Allowed\", \"allowed\", \"not allowed\"]):\n",
    "                        identification[item] = \"Yes\" if any(phrase in line for phrase in [\"Y\", \"YES\", \"yes\", \"Allowed\", \"allowed\"]) else \"No\"\n",
    "        \n",
    "        # Return the anonymized org name and all the extracted info\n",
    "        return filename_anonymized, on_screen_calculator, on_screen_notepad, comfort_breaks, identification\n",
    "\n",
    "# Path to the directory containing the PDF files\n",
    "pdf_directory = \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files\"\n",
    "# Get a list of all PDF files in the directory\n",
    "pdf_files = [os.path.join(pdf_directory, filename) for filename in os.listdir(pdf_directory) if filename.endswith(\".pdf\")]\n",
    "\n",
    "# Process each PDF file and print the extracted info\n",
    "for pdf_file in pdf_files:\n",
    "    info = extract_information_from_pdf(pdf_file)\n",
    "    #print(info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5296f",
   "metadata": {},
   "source": [
    "#### Anonymizing the data to hide organisation name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "# Define a mapping between original organization names and anonymized identifiers\n",
    "org_mapping = {\n",
    "    \"ABP Brief 26 April, 2024.pdf\": \"#001\",\n",
    "    \"ABDO 13 May,2024.pdf\": \"#002\",\n",
    "    \"EMA 23 April, 2024.pdf\": \"#003\",\n",
    "    \"CIIA 2nd May 2024.pdf\": \"#004\",\n",
    "    \"PMI 8 May,2024 CPTU2 Exam.pdf\": \"#005\",\n",
    "    \"SRB - Exam Brief_Senior Bank Resolution Expert_SRB AD 2023 006_Profile 2.docx.pdf\": \"#006\"\n",
    "    \n",
    "}\n",
    "\n",
    "# Defining the function to collect specific information from PDF files\n",
    "def extract_information_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        # Initialize variables to store extracted information\n",
    "        on_screen_calculator = \"Not Available\"\n",
    "        on_screen_notepad = \"Not Available\"\n",
    "        comfort_breaks = \"Not Allowed\"\n",
    "        identification = {\n",
    "            \"Passport\": \"Not Available\",\n",
    "            \"Driver’s License\": \"Not Available\",\n",
    "            \"National ID card\": \"Not Available\",\n",
    "            \"EU ID card\": \"Not Available\",\n",
    "            \"Work ID\": \"Not Available\"\n",
    "        }\n",
    "        # Get the filename (org name) from the path\n",
    "        filename = pdf_file.split(\"/\")[-1]\n",
    "        # Replace org name with anonymized identifier\n",
    "        filename_anonymized = org_mapping.get(filename, filename)\n",
    "        # Loop through each page of the PDF to extract information\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            # Extract on-screen calculator information\n",
    "            if \"On Screen Calculator: Available\" in text:\n",
    "                on_screen_calculator = \"Available\"\n",
    "            # Extract on-screen notepad information\n",
    "            if \"On Screen Notepad: Available\" in text:\n",
    "                on_screen_notepad = \"Available\"\n",
    "            # Extract comfort breaks information\n",
    "            if \"Comfort Breaks\" in text:\n",
    "                if any(phrase in text for phrase in [\"Allowed\", \"Y\", \"YES\", \"yes\"]):\n",
    "                    comfort_breaks = \"Allowed\"\n",
    "                else:\n",
    "                    comfort_breaks = \"Not Allowed\"\n",
    "            # Extract identification information\n",
    "            for item in identification:\n",
    "                if item in text:\n",
    "                    start_idx = text.find(item)\n",
    "                    end_idx = text.find(\"\\n\", start_idx)\n",
    "                    line = text[start_idx:end_idx]\n",
    "                    if any(phrase in line for phrase in [\"Y\", \"YES\", \"yes\", \"Allowed\", \"Not Allowed\", \"allowed\", \"not allowed\"]):\n",
    "                        identification[item] = \"Yes\" if any(phrase in line for phrase in [\"Y\", \"YES\", \"yes\", \"Allowed\", \"allowed\"]) else \"No\"\n",
    "        # Return the extracted information along with anonymized org name\n",
    "        return filename_anonymized, on_screen_calculator, on_screen_notepad, comfort_breaks, identification\n",
    "\n",
    "# Exemple how to set up:\n",
    "pdf_files = [\n",
    "    \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files/ABP Brief 26 April, 2024.pdf\",\n",
    "    \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files/ABDO 13 May,2024.pdf\",\n",
    "    \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files/EMA 23 April, 2024.pdf\",\n",
    "    \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files/CIIA 2nd May 2024.pdf\",\n",
    "    \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files/PMI 8 May,2024 CPTU2 Exam.pdf\",\n",
    "    \"/Users/rennersantana/Desktop/AI - ChatBot/PDF_Files/SRB - Exam Brief_Senior Bank Resolution Expert_SRB AD 2023 006_Profile 2.docx.pdf\"\n",
    "]\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    info = extract_information_from_pdf(pdf_file)\n",
    "    #print(info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e23cea",
   "metadata": {},
   "source": [
    "#### We initialise lists to store extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store extracted information\n",
    "filename_list = []\n",
    "calculator_list = []\n",
    "notepad_list = []\n",
    "comfort_breaks_list = []\n",
    "passport_list = []\n",
    "drivers_license_list = []\n",
    "national_id_card_list = []\n",
    "eu_id_card_list = []\n",
    "work_id_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379bf59b",
   "metadata": {},
   "source": [
    "#### Loop through each PDF file in directory so we can save the dataset later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd9c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information_from_pdf(pdf_file):\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        # Initialize variables to store extracted information\n",
    "        on_screen_calculator = \"Not Available\"\n",
    "        on_screen_notepad = \"Not Available\"\n",
    "        comfort_breaks = \"Not Allowed\"\n",
    "        identification = {\n",
    "            \"Passport\": \"Not Available\",\n",
    "            \"Driver’s License\": \"Not Available\",\n",
    "            \"National ID card\": \"Not Available\",\n",
    "            \"EU ID card\": \"Not Available\",\n",
    "            \"Work ID\": \"Not Available\"\n",
    "        }\n",
    "        # Get the filename (org name) from the path\n",
    "        filename = pdf_file.split(\"/\")[-1]\n",
    "        # Replace org name with anonymized identifier\n",
    "        filename_anonymized = org_mapping.get(filename, filename)\n",
    "        # Loop through each page of the PDF to extract information\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            # Extract on-screen calculator information\n",
    "            if \"On Screen Calculator: Available\" in text:\n",
    "                on_screen_calculator = \"Available\"\n",
    "            # Extract on-screen notepad information\n",
    "            if \"On Screen Notepad: Available\" in text:\n",
    "                on_screen_notepad = \"Available\"\n",
    "            # Extract comfort breaks information\n",
    "            if \"Comfort Breaks\" in text:\n",
    "                if any(phrase in text for phrase in [\"Allowed\", \"Y\", \"YES\", \"yes\"]):\n",
    "                    comfort_breaks = \"Allowed\"\n",
    "                else:\n",
    "                    comfort_breaks = \"Not Allowed\"\n",
    "            # Extract identification information\n",
    "            for item in identification:\n",
    "                if item in text:\n",
    "                    start_idx = text.find(item)\n",
    "                    end_idx = text.find(\"\\n\", start_idx)\n",
    "                    line = text[start_idx:end_idx]\n",
    "                    if any(phrase in line for phrase in [\"Y\", \"YES\", \"yes\", \"Allowed\", \"Not Allowed\", \"allowed\", \"not allowed\"]):\n",
    "                        identification[item] = \"Yes\" if any(phrase in line for phrase in [\"Y\", \"YES\", \"yes\", \"Allowed\", \"allowed\"]) else \"No\"\n",
    "        # Return the extracted information along with anonymized org name\n",
    "        return filename_anonymized, on_screen_calculator, on_screen_notepad, comfort_breaks, identification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b28b393",
   "metadata": {},
   "source": [
    "#### Create a DataFrame to store extracted information and save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each PDF file in the directory\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_file = os.path.join(pdf_directory, filename)\n",
    "        try:\n",
    "            # Extract information from the current PDF file\n",
    "            info = extract_information_from_pdf(pdf_file)\n",
    "            print(f\"Processed file: {filename}, Info: {info}\")\n",
    "            \n",
    "            # Append extracted information to lists\n",
    "            filename_list.append(info[0])\n",
    "            calculator_list.append(info[1])\n",
    "            notepad_list.append(info[2])\n",
    "            comfort_breaks_list.append(info[3])\n",
    "            passport_list.append(info[4][\"Passport\"])\n",
    "            drivers_license_list.append(info[4][\"Driver’s License\"])\n",
    "            national_id_card_list.append(info[4][\"National ID card\"])\n",
    "            eu_id_card_list.append(info[4][\"EU ID card\"])\n",
    "            work_id_list.append(info[4][\"Work ID\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "# Create a DataFrame to store the extracted information\n",
    "data = {\n",
    "    \"Filename\": filename_list,\n",
    "    \"On Screen Calculator\": calculator_list,\n",
    "    \"On Screen Notepad\": notepad_list,\n",
    "    \"Comfort Breaks\": comfort_breaks_list,\n",
    "    \"Passport\": passport_list,\n",
    "    \"Driver’s License\": drivers_license_list,\n",
    "    \"National ID card\": national_id_card_list,\n",
    "    \"EU ID card\": eu_id_card_list,\n",
    "    \"Work ID\": work_id_list\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc40d1d",
   "metadata": {},
   "source": [
    "#### Once information is collected it is stored in the path of our choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a118c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to save the CSV file\n",
    "csv_file_path = \"/Users/rennersantana/Desktop/AI - ChatBot/extracted_information.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70a8ff",
   "metadata": {},
   "source": [
    "#### Save DataFrame to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dd2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3b3d4",
   "metadata": {},
   "source": [
    "#### Print confirmation file was saved in the specific path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65863543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confirmation message\n",
    "print(\"Extracted information saved to:\", csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72469f7",
   "metadata": {},
   "source": [
    "#### we load the data, reads the original CSV file containing exam-relate information.\n",
    "\n",
    "\n",
    "#### We standardize text to ensure text data in specific columns is consistently formatted.\n",
    "\n",
    "\n",
    "#### One-Hot Enconding so we can convert categorical text data into a format suitable for machine learning by creating binary columns.\n",
    "\n",
    "#### We save the Preprocessed data and writes the transformed data to a new CSV file for further use.\n",
    "\n",
    "\n",
    "#### We catch and print any errors that occur during the process\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load SpaCy's English tokenizer\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "try:\n",
    "    # Load the data\n",
    "    df = pd.read_csv(\"/Users/rennersantana/Desktop/AI - ChatBot/extracted_information.csv\")\n",
    "    print(\"Data loaded successfully:\")\n",
    "    #print(df.head())\n",
    "\n",
    "    # Standardizing text data\n",
    "    df['On Screen Calculator'] = df['On Screen Calculator'].str.title()\n",
    "    df['On Screen Notepad'] = df['On Screen Notepad'].str.title()\n",
    "    df['Comfort Breaks'] = df['Comfort Breaks'].str.title()\n",
    "    #print(\"\\nText data standardized. Here's a preview:\")\n",
    "    #print(df.head())\n",
    "\n",
    "    # Encoding categorical data using one-hot encoding\n",
    "    df_encoded = pd.get_dummies(df, columns=[\n",
    "        'On Screen Calculator', 'On Screen Notepad', 'Comfort Breaks',\n",
    "        'Passport', 'Driver’s License', 'National ID card', 'EU ID card', 'Work ID'\n",
    "    ])\n",
    "    #print(\"\\nCategorical data encoded. Here's a preview of the new columns:\")\n",
    "    #print(df_encoded.columns)\n",
    "\n",
    "    # Save the preprocessed data\n",
    "    df_encoded.to_csv(\"/Users/rennersantana/Desktop/AI - ChatBot/preprocessed_extracted_information.csv\", index=False)\n",
    "    print(\"\\nPreprocessed data saved to '/Users/rennersantana/Desktop/AI - ChatBot/preprocessed_extracted_information.csv'\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70adf400",
   "metadata": {},
   "source": [
    "#### spacy: A library for advanced natural language processing in Python. Here it's used to load a tokenizer with lemmatization.\n",
    "\n",
    "#### sklearn: A machine learning library. Specifically, TfidfVectorizer converts text data into numerical format (TF-IDF), and cosine_similarity measures similarity between vectors.\n",
    "\n",
    "#### openai: Used to interact with the OpenAI GPT-3.5 API for generating detailed responses.\n",
    "\n",
    "#### re: The regular expression library used for pattern matching.\n",
    "#### nlp: Loads SpaCy's English tokenizer for processing text data.\n",
    "#### client: Initializes the OpenAI API client with the provided API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "# Load SpaCy's English tokenizer with lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client = OpenAI(api_key='sk-proj-4WpSpnKeG7r11ZB3eYfhT3BlbkFJAKW3GKwmt84S5c6lRxUU')\n",
    "\n",
    "# Load the preprocessed data\n",
    "df_encoded = pd.read_csv(\"/Users/rennersantana/Desktop/AI - ChatBot/preprocessed_extracted_information.csv\")\n",
    "\n",
    "# Define a function to preprocess questions with lemmatization\n",
    "def preprocess_text(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text.lower())])\n",
    "\n",
    "# Setup vectorization and NLP processing\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "questions_to_columns = {\n",
    "    # On Screen Calculator Availability\n",
    "    \"is an on-screen calculator available during the exam?\": \"On Screen Calculator_Available\",\n",
    "    \"can i use an on-screen calculator during the exam?\": \"On Screen Calculator_Available\",\n",
    "    \"will there be an on-screen calculator available for the test?\": \"On Screen Calculator_Available\",\n",
    "    \"is the on-screen calculator provided?\": \"On Screen Calculator_Available\",\n",
    "    \"do we have access to an on-screen calculator in the exam?\": \"On Screen Calculator_Available\",\n",
    "    \n",
    "    # On Screen Notepad Availability\n",
    "    \"is there an on-screen notepad available?\": \"On Screen Notepad_Available\",\n",
    "    \"can i use an on-screen notepad during the exam?\": \"On Screen Notepad_Available\",\n",
    "    \"will an on-screen notepad be provided during the test?\": \"On Screen Notepad_Available\",\n",
    "    \"is the on-screen notepad accessible during the exam?\": \"On Screen Notepad_Available\",\n",
    "    \"do we have access to an on-screen notepad?\": \"On Screen Notepad_Available\",\n",
    "    \n",
    "    # Comfort Breaks Allowed\n",
    "    \"are comfort breaks allowed during the exam?\": \"Comfort Breaks_Allowed\",\n",
    "    \"can i take a comfort break during the test?\": \"Comfort Breaks_Allowed\",\n",
    "    \"is it possible to have comfort breaks during the exam?\": \"Comfort Breaks_Allowed\",\n",
    "    \"will comfort breaks be permitted during the exam?\": \"Comfort Breaks_Allowed\",\n",
    "    \"are we allowed to have comfort breaks?\": \"Comfort Breaks_Allowed\",\n",
    "    \n",
    "    # Passport Requirement\n",
    "    \"do i need a passport to take the exam?\": \"Passport_Yes\",\n",
    "    \"is a passport required for the test?\": \"Passport_Yes\",\n",
    "    \"will i need to bring a passport for the exam?\": \"Passport_Yes\",\n",
    "    \"is a passport necessary for the exam?\": \"Passport_Yes\",\n",
    "    \"do i have to bring my passport to the exam?\": \"Passport_Yes\",\n",
    "    \n",
    "    # Driver’s License as Identification\n",
    "    \"can i use my driver’s license as identification for the exam?\": \"Driver’s License_Yes\",\n",
    "    \"is a driver’s license acceptable as id for the test?\": \"Driver’s License_Yes\",\n",
    "    \"will a driver’s license be sufficient as identification for the exam?\": \"Driver’s License_Yes\",\n",
    "    \"can my driver’s license be used for identification purposes?\": \"Driver’s License_Yes\",\n",
    "    \"is it okay to use my driver’s license for the exam id?\": \"Driver’s License_Yes\",\n",
    "    \n",
    "    # National ID Card Requirement\n",
    "    \"do i need a national id card to take the exam?\": \"National ID card_Yes\",\n",
    "    \"is a national id card required for the test?\": \"National ID card_Yes\",\n",
    "    \"will i need to bring my national id card for the exam?\": \"National ID card_Yes\",\n",
    "    \"is a national id card necessary for the exam?\": \"National ID card_Yes\",\n",
    "    \"do i have to bring my national id card to the exam?\": \"National ID card_Yes\",\n",
    "    \n",
    "    # EU ID Card as Identification\n",
    "    \"can i use my eu id card as identification for the exam?\": \"EU ID card_Yes\",\n",
    "    \"is an eu id card acceptable as id for the test?\": \"EU ID card_Yes\",\n",
    "    \"will an eu id card be sufficient as identification for the exam?\": \"EU ID card_Yes\",\n",
    "    \"can my eu id card be used for identification purposes?\": \"EU ID card_Yes\",\n",
    "    \"is it okay to use my eu id card for the exam id?\": \"EU ID card_Yes\",\n",
    "    \n",
    "    # Work ID as Identification\n",
    "    \"is a work id an acceptable form of identification for the exam?\": \"Work ID_Yes\",\n",
    "    \"can i use my work id for the test?\": \"Work ID_Yes\",\n",
    "    \"will a work id be sufficient as identification for the exam?\": \"Work ID_Yes\",\n",
    "    \"is it possible to use a work id for the exam?\": \"Work ID_Yes\",\n",
    "    \"do we need to bring a work id for the test?\": \"Work ID_Yes\"\n",
    "}\n",
    "questions = list(questions_to_columns.keys())\n",
    "processed_questions = [preprocess_text(question) for question in questions]\n",
    "question_vectors = vectorizer.fit_transform(processed_questions)\n",
    "\n",
    "def find_closest_question(user_query, threshold=0.75):\n",
    "    processed_query = preprocess_text(user_query)\n",
    "    query_vector = vectorizer.transform([processed_query])\n",
    "    similarities = cosine_similarity(query_vector, question_vectors)\n",
    "    max_similarity = max(similarities[0])\n",
    "    if max_similarity < threshold:\n",
    "        return None\n",
    "    return questions[similarities.argmax()]\n",
    "\n",
    "def answer_question(question, data_frame, org_code):\n",
    "    matched_question = find_closest_question(question)\n",
    "    if matched_question:\n",
    "        column = questions_to_columns[matched_question]\n",
    "        basic_response = \"Yes\" if data_frame.iloc[org_code][column] else \"No\"\n",
    "        # Use GPT to elaborate on the basic response with context\n",
    "        org_details = data_frame.iloc[org_code].to_dict()\n",
    "        full_query = f\"{matched_question} Answer: {basic_response}. Here are the details for organization {org_code}: {org_details}. Can you provide more details?\"\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": full_query}],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    else:\n",
    "        # Fallback to GPT if no direct match is found\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": question}],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "def contains_org_code(user_input):\n",
    "    # Check if the input contains an organization code like #001, #002, etc.\n",
    "    match = re.search(r\"#(\\d{3})\", user_input)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Chatbot interaction loop\n",
    "print(\"Welcome to the Exam Info Chatbot! Ask me anything about exam provisions. Type 'quit' to exit.\")\n",
    "pending_question = None\n",
    "org_code = None\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        print(\"Thank you for using the Chatbot. Goodbye!\")\n",
    "        break\n",
    "    if pending_question:\n",
    "        code = contains_org_code(user_input)\n",
    "        if code is not None:\n",
    "            # Process the pending question with the provided organization code\n",
    "            org_code = code\n",
    "            response = answer_question(pending_question, df_encoded, org_code)\n",
    "            print(\"Chatbot: \", response)\n",
    "            pending_question = None\n",
    "        else:\n",
    "            print(\"Chatbot: Please specify the organization code (e.g., #001).\")\n",
    "    else:\n",
    "        code = contains_org_code(user_input)\n",
    "        if code is not None:\n",
    "            org_code = code\n",
    "            response = answer_question(user_input, df_encoded, org_code)\n",
    "            print(\"Chatbot: \", response)\n",
    "        else:\n",
    "            pending_question = user_input\n",
    "            print(\"Chatbot: Please specify the organization code (e.g., #001).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed16933",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef105d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
